<html>
<head>
  <title>Chuan He's HomePage</title>
</head>
<! body background="paper.jpg"> 
<! body background="paper.jpg" bgcolor="silver"> 

<a name="topp"></a>

<table border="0" height="285" width="75%">
  <tb>
   <tr>

    <td width="30%"><img src="chuanhe.jpg" height="190" width="147"></td>

    <td width="60%">

      <p><font size="5">
      <b>Chuan He</b><br>
      <br>
      <p><font size="3">
        PhD candidate<br>
        Department of Industrial and Systems Engineering<br>
        University of Minnesota<br>
      <br> 

        <b>Email:</b> he000233@umn.edu<br>

    </td>

  </tr>

  <tr>

    <td colspan="2">
     <p>&nbsp;</p>


    Welcome to my homepage! &nbsp;</p>    

    I am currently a PhD student in the <a target="_blank" href="https://cse.umn.edu/isye">Department of Industrial and Systems Engineering</a> at <a target="_blank" href="https://twin-cities.umn.edu/">University of Minnesota</a>, 
    under the supervision of <a target="_blank" href="https://zhaosong-lu.github.io/index.html">Professor Zhaosong Lu</a>. Previously, I received my bachelor's degree from the <a target="_blank" href="https://math.xmu.edu.cn/en/">School of Mathematical Sciences</a> at <a target="_blank" href="https://en.xmu.edu.cn/">Xiamen University</a>, 
    with thesis advised by <a target="_blank" href="https://www.math.fsu.edu/~whuang2/">Professor Wen Huang</a>. I am particularly interested in algorithm design and analysis for optimization problems arising in fields such as statistics, engineering and machine learning. 
    My current research focuses on new complexity theory for continuous optimization, motivated by modern machine learning problems.

     <p>&nbsp;</p>

     <b>Research Papers</b> 
      <ul>
       <li><a target="_blank" href="https://arxiv.org/abs/2301.04204">A Newton-CG based barrier-augmented Lagrangian method for general nonconvex conic optimization</a> (with H. Huang and Z. Lu), submitted.</li> 
       <li><a target="_blank">A parameter-free conditional gradient method for composite minimization under HÃ¶lder condition</a> (with M. Ito and Z. Lu), accepted by <em>Journal of Machine Learning Research</em>.</li> 
       <li><a target="_blank" href="https://arxiv.org/pdf/2206.03531.pdf">Decision rule approaches for pessimistic bilevel linear programs under moment ambiguity with facility location applications</a> (with A. Goyal and Y. Zhang), accepted by <em>INFORMS Journal on Computing</em>.</li> 
       <li><a target="_blank" href="https://arxiv.org/abs/2301.03139">A Newton-CG based augmented Lagrangian method for finding a second-order stationary point of nonconvex equality constrained optimization with complexity guarantees</a> (with Z. Lu and T. K. Pong), accepted by <em>SIAM Journal on Optimization</em>.</li> 
       <li><a target="_blank" href="https://arxiv.org/pdf/2207.05697.pdf">A Newton-CG based barrier method for finding a second-order stationary point of nonconvex conic optimization with complexity guarantees</a> (with Z. Lu), accepted by <em>SIAM Journal on Optimization</em>.</li> 
       

     </ul>
     <b>Teaching Assistant</b>
      <ul>
        <li> IE 8564: Optimization for machine learning, Fall 2022.</li>
        <li> IE 5533: Operations research for data science, Fall 2022.</li>
        <li> IE 8534: Advanced topics in optimization for machine learning, Fall 2020, 2021.</li>
        <li> IE 5561: Analytics and data-driven decision making, Spring 2021.</li>
        <li> IE 8532: Stochastic process and queuing systems, Fall 2020.</li>
        <li> IE 3522: Quality engineering and reliability, Spring 2020.</li> 
        <li> IE 3521: Statistics, quality, and reliability, Fall 2019.</li>
      </ul> 






</body></html>
